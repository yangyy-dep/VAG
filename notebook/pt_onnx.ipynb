{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#将pytorch模型转换为onnx模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import dnnlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import legacy\n",
    "import functools\n",
    "import click\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#需要调整的有1.权重文件的路径；2.onnx模型的输出路径及名称\n",
    "# 加载模型\n",
    "device = torch.device('cpu')\n",
    "source = r'models\\pkl\\network-snapshot-005000.pkl'\n",
    "with dnnlib.util.open_url(source) as f:\n",
    "        GG = legacy.load_network_pkl(f)['G'].to(device)\n",
    "GG.forward = functools.partial(GG.forward, force_fp32=True)\n",
    "# 输入\n",
    "dummy_input = torch.from_numpy(np.random.RandomState(0).randn(1, GG.z_dim)).to(device)\n",
    "label = torch.zeros([1, GG.c_dim], device=device)\n",
    "#转换onnx模型\n",
    "in_names = [\"z\"] + [\"c\"]\n",
    "out_names = [\"Y\"]\n",
    "torch.onnx.export(model=GG,\n",
    "                      args=(dummy_input, label),\n",
    "                      f=\"stylegan2.onnx\",\n",
    "                      input_names=in_names,\n",
    "                      output_names=out_names,\n",
    "                      verbose=False,\n",
    "                      opset_version=10,\n",
    "                      export_params=False,\n",
    "                      do_constant_folding=False,\n",
    "                      operator_export_type=torch.onnx.OperatorExportTypes.ONNX)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#不同模型生成图片对比"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#pytorch模型生成图片\n",
    "import os\n",
    "import re\n",
    "from typing import List, Optiona\n",
    "import click\n",
    "import dnnlib\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import legacy\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def num_range(s: str) -> List[int]:\n",
    "    '''Accept either a comma separated list of numbers 'a,b,c' or a range 'a-c' and return as a list of ints.'''\n",
    "\n",
    "    range_re = re.compile(r'^(\\d+)-(\\d+)$')\n",
    "    m = range_re.match(s)\n",
    "    if m:\n",
    "        return list(range(int(m.group(1)), int(m.group(2)) + 1))\n",
    "    vals = s.split(',')\n",
    "    return [int(x) for x in vals]\n",
    "#需要调整的有1.network_pkl，权重文件；2.seeds可以修改；3.outdir，生成图片的路径根据需要修改\n",
    "# ----------------------------------------------------------------------------\n",
    "def generate_images():\n",
    "    network_pkl = r'models\\pkl\\network-snapshot-005000.pkl'\n",
    "    seeds = [85,265,297,849]\n",
    "    outdir = r'results/'\n",
    "    projected_w = None\n",
    "    class_idx = None\n",
    "    print('Loading networks from \"%s\"...' % network_pkl)\n",
    "    device = torch.device('cuda')\n",
    "    with dnnlib.util.open_url(network_pkl) as f:\n",
    "        G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    if projected_w is not None:\n",
    "        if seeds is not None:\n",
    "            print('warn: --seeds is ignored when using --projected-w')\n",
    "        print(f'Generating images from projected W \"{projected_w}\"')\n",
    "        ws = np.load(projected_w)['w']\n",
    "        ws = torch.tensor(ws, device=device)\n",
    "        assert ws.shape[1:] == (G.num_ws, G.w_dim)\n",
    "        for idx, w in enumerate(ws):\n",
    "            img = G.synthesis(w.unsqueeze(0), noise_mode='random')\n",
    "            img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "            img = PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/proj{idx:02d}.png')\n",
    "        return\n",
    "\n",
    "    if seeds is None:\n",
    "        ctx.fail('--seeds option is required when not using --projected-w')\n",
    "\n",
    "\n",
    "    label = torch.zeros([1, G.c_dim], device=device)\n",
    "    if G.c_dim != 0:\n",
    "        if class_idx is None:\n",
    "            ctx.fail('Must specify class label with --class when using a conditional network')\n",
    "        label[:, class_idx] = 1\n",
    "    else:\n",
    "        if class_idx is not None:\n",
    "            print('warn: --class=lbl ignored when running on an unconditional network')\n",
    "\n",
    "    # Generate images.\n",
    "    for seed_idx, seed in enumerate(seeds):\n",
    "        print('Generating image for seed %d (%d/%d) ...' % (seed, seed_idx, len(seeds)))\n",
    "        z = torch.from_numpy(np.random.RandomState(seed).randn(1, G.z_dim)).to(device)\n",
    "        img = G(z, label, truncation_psi=0.7, noise_mode='random')\n",
    "        img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "        PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/seed{seed:04d}.png')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_images()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#onnx模型生成图片\n",
    "import dnnlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import legacy\n",
    "import functools\n",
    "import click\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import onnxruntime"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#需要调整的有1.onnx模型的路径；2.图片保存的路径\n",
    "# 创建一个InferenceSession的实例，并将模型的地址传递给该实例\n",
    "onnx_model = onnxruntime.InferenceSession('results/stylegan2.onnx')\n",
    "# 输入\n",
    "dummy_input = np.random.randn(1, 512).astype(np.double)\n",
    "# 生成图片\n",
    "output_name = onnx_model.get_outputs()[0].name\n",
    "outputs = onnx_model.run([output_name], {onnx_model.get_inputs()[0].name: dummy_input})[0]\n",
    "output = (outputs.squeeze().transpose((1, 2, 0)) * 127.5 + 128)\n",
    "image = np.clip(output, 0, 255).astype(np.uint8)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(\"./results/result.png\",image)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
